#!/usr/bin/env python3
"""
Simple ProcessIQ Demo Test
Tests the core functionality without complex dependencies
"""

import sys
import tempfile
from pathlib import Path
import pandas as pd
import json
from datetime import datetime

# Create sample data and Excel file to demonstrate the concept
def create_sample_demo():
    """Create a simplified version of the demo"""
    print("üéØ ProcessIQ RPA Demo - Simplified Version")
    print("=" * 50)
    
    # Create output directory
    output_dir = Path(tempfile.mkdtemp()) / "processiq_demo"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"üìÅ Output directory: {output_dir}")
    
    # Step 1: Generate sample data (simulating web scraping)
    print("üìä Step 1: Generating sample sales data...")
    import numpy as np
    np.random.seed(42)
    
    n_records = 100
    regions = ['North', 'South', 'East', 'West', 'Central']
    products = ['Software', 'Hardware', 'Consulting', 'Training', 'Support']
    salespeople = [f'Sales_{i:02d}' for i in range(1, 11)]
    
    data = {
        'transaction_id': range(1, n_records + 1),
        'date': pd.date_range('2024-01-01', periods=n_records, freq='D'),
        'salesperson': np.random.choice(salespeople, n_records),
        'region': np.random.choice(regions, n_records),
        'product_category': np.random.choice(products, n_records),
        'sales_amount': np.random.lognormal(mean=8, sigma=1, size=n_records).round(2),
        'customer_type': np.random.choice(['Enterprise', 'SMB', 'Startup'], n_records, p=[0.3, 0.5, 0.2])
    }
    
    df = pd.DataFrame(data)
    csv_file = output_dir / "sales_data.csv"
    df.to_csv(csv_file, index=False)
    print(f"   ‚úÖ Generated {len(df)} records")
    
    # Step 2: Data analysis (simulating processing)
    print("üîÑ Step 2: Processing and analyzing data...")
    analysis = {
        "total_sales": float(df['sales_amount'].sum()),
        "average_sale": float(df['sales_amount'].mean()),
        "total_transactions": len(df),
        "sales_by_region": df.groupby('region')['sales_amount'].sum().to_dict(),
        "sales_by_product": df.groupby('product_category')['sales_amount'].sum().to_dict(),
    }
    print(f"   ‚úÖ Total Sales: ${analysis['total_sales']:,.2f}")
    print(f"   ‚úÖ Average Sale: ${analysis['average_sale']:,.2f}")
    
    # Step 3: Create Excel output (simulating Excel generation)
    print("üìà Step 3: Creating Excel output...")
    try:
        import openpyxl
        
        # Create Excel file with basic formatting
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Sales Analysis"
        
        # Add header
        ws['A1'] = 'ProcessIQ Sales Analysis Dashboard'
        ws['A1'].font = openpyxl.styles.Font(size=16, bold=True)
        
        # Add metrics
        row = 3
        ws[f'A{row}'] = 'Total Sales'
        ws[f'B{row}'] = f"${analysis['total_sales']:,.2f}"
        ws[f'A{row+1}'] = 'Average Sale'  
        ws[f'B{row+1}'] = f"${analysis['average_sale']:,.2f}"
        ws[f'A{row+2}'] = 'Total Transactions'
        ws[f'B{row+2}'] = analysis['total_transactions']
        
        # Add raw data
        ws2 = wb.create_sheet("Raw Data")
        for r in range(len(df)):
            for c, col in enumerate(df.columns):
                if r == 0:
                    ws2.cell(row=r+1, column=c+1, value=col)
                else:
                    ws2.cell(row=r+1, column=c+1, value=str(df.iloc[r-1, c]))
        
        excel_file = output_dir / "sales_analysis.xlsx"
        wb.save(excel_file)
        print(f"   ‚úÖ Excel file created: {excel_file.name}")
        
    except ImportError:
        print("   ‚ö†Ô∏è  openpyxl not available, skipping Excel creation")
        excel_file = None
    
    # Step 4: Generate summary report
    print("üìã Step 4: Generating summary report...")
    summary = {
        "demo_id": f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "execution_time": datetime.now().isoformat(),
        "success": True,
        "steps_completed": 4,
        "data_processed": {
            "records": len(df),
            "columns": len(df.columns),
            "file_size_kb": round(csv_file.stat().st_size / 1024, 2)
        },
        "analysis_results": analysis,
        "generated_files": [
            str(csv_file.name),
            str(excel_file.name) if excel_file else None
        ]
    }
    
    report_file = output_dir / "demo_summary.json"
    with open(report_file, 'w') as f:
        json.dump(summary, f, indent=2, default=str)
    
    print("\nüéâ Demo Results:")
    print(f"   ‚úÖ Success: True")
    print(f"   üìä Records processed: {len(df)}")
    print(f"   üìÅ Files created: {len([f for f in [csv_file, excel_file, report_file] if f])}")
    print(f"   üìÇ Output location: {output_dir}")
    
    print(f"\nüìÅ Generated Files:")
    for file_path in output_dir.glob("*"):
        size_kb = round(file_path.stat().st_size / 1024, 2)
        print(f"   üìÑ {file_path.name} ({size_kb} KB)")
    
    print(f"\nüéØ ProcessIQ RPA Capabilities Demonstrated:")
    print(f"   ‚Ä¢ Data generation and processing")
    print(f"   ‚Ä¢ Multi-format output (CSV, Excel, JSON)")
    print(f"   ‚Ä¢ Automated reporting and analysis")
    print(f"   ‚Ä¢ File management and organization")
    print(f"   ‚Ä¢ Error handling and progress tracking")
    
    return True

if __name__ == "__main__":
    try:
        success = create_sample_demo()
        print(f"\n{'='*50}")
        print("‚úÖ ProcessIQ Demo completed successfully!")
        print("This demonstrates the core RPA orchestration capabilities.")
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)